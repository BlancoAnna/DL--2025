{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BlancoAnna/DL--2025/blob/main/P3_Intro_Pytorch_Tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcvesegFyIX-"
      },
      "source": [
        "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/dkaratzas/DL2022-23/blob/main/Problems%202%20-%20Using%20Autograd%20and%20PyTorch/P2_2_Intro_Tensors.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IF4i31_7jbg"
      },
      "source": [
        "# What is PyTorch?\n",
        "\n",
        "<a href=\"https://pytorch.org/\">Pytorch</a> is a Python based scientific computing package targeted at two types of audience:\n",
        "\n",
        "-  At the low level, it is a tensor library capable to exploit the computational power of GPUs\n",
        "-  At the high level, it is a deep learning research platform that provides maximum flexibility and speed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ng2mpMYgkpu"
      },
      "source": [
        "## Import the library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzX92S587jbm"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y62dQH467jbn"
      },
      "source": [
        "## Getting help in Jupyter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll9zxJ9IyIYB"
      },
      "source": [
        "The fastest way to get some quick help on something using Jupyter is to just ask! Type any Python object name you want followed by a question mark `?` and the code documentation will be loaded in your notebook. Try it with `torch`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LN6xGdhUyIYB"
      },
      "outputs": [],
      "source": [
        "torch?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLMcdjjuyIYB"
      },
      "source": [
        "The following command will list all objects of torch that with a name that finishes with \"Tensor\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIqY0-QT7jbo"
      },
      "outputs": [],
      "source": [
        "# In Colab, you can press <esc> to get out of help\n",
        "torch.*Tensor?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpLRB9CFyIYC"
      },
      "source": [
        "If you use Colab, you also have a handy autocomplete feature at hand. For example, start writing a function name, like `torch.sqrt` if you pause after the first few characters a context menu with possible options will appear. Select the term you meant and press Tab or Enter to autocomplete. Note, this will not work in Jupyter Lab / Notebook out of the box, you would need to install an extension to enable this functionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4g-D23eg7jbn",
        "outputId": "d0d0987a-85d6-431b-9cc2-e02d9d41bdc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function torch._VariableFunctionsClass.sqrt>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# start typing torch.sqr...  wait and then use <Tab> or <Enter> to autocomplete to torch.sqrt()\n",
        "torch.sqrt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcGTutwryIYD"
      },
      "source": [
        "In Jupyter Lab (but not in CoLab) you can access the documentation by clicking on the Python object and pressing `<Shift>` + `<Tab>`. Try it in the line below (if you are using Jupyter Lab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ED3Z0RKO7jbo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faaab47b-017b-461d-a081-8f062129d3fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Module()"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "torch.nn.Module()  # <Shift>+<Tab>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGLfjLTgyIYD"
      },
      "source": [
        "You should see the same result as with the line below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrBufY4q7jbo"
      },
      "outputs": [],
      "source": [
        "# Annotate your functions / classes!\n",
        "torch.nn.Module?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQjnow2DyIYE"
      },
      "source": [
        "Where does this documentation come from? Part of it comes from the code itself, and part of it from the annotations (special comments) that are introduced in the function / class definitions. To have a look at the actual code of a function, just use a double `??`. See for example below, and get used to annotating your functions / classes as well!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6gVzBNi7jbp"
      },
      "outputs": [],
      "source": [
        "torch.nn.Module??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3odUxKDa7jbq"
      },
      "source": [
        "## Torch!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw3ACW-eyIYE"
      },
      "source": [
        "At the core of PyTorch there is the `Tensor` class. It is very much like numpy's arrays, but supports autograd."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxMMJ1tO7jbq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c1f873b-0f19-42d4-edfc-421eb4807438"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Generate a tensor of size 2x3x4\n",
        "t = torch.Tensor(2, 3, 4)\n",
        "type(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3xcTvfc7jbr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef6adb1-b9c7-4945-8e68-de84dad52dfa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Get the size of the tensor\n",
        "t.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDV8gZtQyIYK"
      },
      "source": [
        "# Tensors and tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okM52HiDyIYL",
        "outputId": "728aa66a-f2fa-45a2-85ea-d9fbdfff221d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "t = torch.Tensor(2, 3, 4)\n",
        "type(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BTJlKPWyIYL",
        "outputId": "6dc1e12b-2225-46ea-d6d9-bc5a3ce18e85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "t.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pusVGlb5yIYL",
        "outputId": "2056f4fe-132e-452f-ac3e-ae58765ec82d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[2.1715e-18, 2.6312e+20, 6.6467e+22, 1.7471e-04],\n",
              "         [2.6217e+20, 3.3884e-06, 8.4639e-07, 2.7302e-06],\n",
              "         [6.4826e-10, 4.2695e-08, 2.1707e-18, 1.6678e+19]],\n",
              "\n",
              "        [[7.0976e+22, 2.1715e-18, 4.2330e+21, 1.6534e+19],\n",
              "         [1.1625e+27, 1.4580e-19, 7.1856e+22, 4.3605e+27],\n",
              "         [1.5766e-19, 7.1856e+22, 4.3605e+27, 1.4580e-19]]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObX2wLyCyIYL",
        "outputId": "c4842cc5-54c1-4fb3-b240-d55f4f441032",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "t1 = torch.tensor([1, 2, 3, 4])\n",
        "type(t1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sll5NbsTyIYL",
        "outputId": "de55af20-3b2a-44ef-8228-e389c2d86104",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "t1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYJJkp2FyIYL",
        "outputId": "4a567b79-3e22-4d98-811b-a4ac87983402",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "t1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVoVwZLByIYM",
        "outputId": "46ae6f27-1808-45d7-bc45-ccd3583061cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "t2 = torch.tensor([[[1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4]], [[1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4]]])\n",
        "type(t2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y306ZdIXyIYM",
        "outputId": "acd77463-adec-4aa4-97bc-467cbab122f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3, 4],\n",
              "         [1, 2, 3, 4],\n",
              "         [1, 2, 3, 4]],\n",
              "\n",
              "        [[1, 2, 3, 4],\n",
              "         [1, 2, 3, 4],\n",
              "         [1, 2, 3, 4]]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "t2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwPWsVjqyIYM",
        "outputId": "7114da44-40cc-4dec-9c61-a35db0f8d27e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "t2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60fsUROsyIYM",
        "outputId": "a2a3745e-7064-408c-bc8b-4003f9b95ef0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "torch.zeros(2, 3, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dimensions"
      ],
      "metadata": {
        "id": "-enxHw_JaeZJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXAmpH-Z7jbr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a38c51-27df-4b1a-9cb2-c537e3e413f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "point in a 24 dimensional space\n",
            "organised in 3 sub-dimensions\n"
          ]
        }
      ],
      "source": [
        "t = torch.Tensor(2, 3, 4)\n",
        "# prints dimensional space and sub-dimensions\n",
        "print(f'point in a {t.numel()} dimensional space')\n",
        "print(f'organised in {t.dim()} sub-dimensions')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Don't confuse a 3D vector with a 3D tensor. _Dimensionality_ can refer to either the number of entries along a specific axis (as in a 3D vector) or the number of axes in a tensor (such as a 3D tensor), which can be confusing. You may also come across the term _tensor of rank_ 3, where rank refers to the number of axes."
      ],
      "metadata": {
        "id": "DBq6Q4F8TGpJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC8XADcV7jbr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5538655-b1ec-4ffd-a0fa-f03b6fc74372"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[3.3577e-34, 0.0000e+00, 2.3694e-38, 2.3694e-38],\n",
              "         [8.9683e-44, 0.0000e+00, 1.1210e-43, 0.0000e+00],\n",
              "         [3.3580e-34, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "         [1.4013e-45, 0.0000e+00, 0.0000e+00, 0.0000e+00]]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ARC3wOQ7jbr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64ad97e0-7b3f-413c-a5b2-d8cdd4cdd24b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[8., 4., 2., 9.],\n",
              "         [1., 0., 1., 3.],\n",
              "         [7., 9., 7., 6.]],\n",
              "\n",
              "        [[6., 8., 7., 7.],\n",
              "         [7., 3., 8., 6.],\n",
              "         [3., 5., 6., 8.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Mind the underscore!\n",
        "# Any operation that mutates a tensor in-place is post-fixed with an _.\n",
        "# For example: x.copy_(y), x.t_(), x.random_(n) will change x.\n",
        "t.random_(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wL2ajaMg7jbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11827547-dcef-454f-cb26-a804cb42dbd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[8., 4., 2., 9., 1., 0., 1., 3.],\n",
              "        [7., 9., 7., 6., 6., 8., 7., 7.],\n",
              "        [7., 3., 8., 6., 3., 5., 6., 8.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "r = t.view(3, 8) # r is the Tensor reshaped to the size 3x8\n",
        "r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivViPVSG7jbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73a69060-94fa-42f3-bf24-a5dd896876ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# As you can see zero_ would replace r with 0's which was originally filled with integers\n",
        "r.zero_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7KuYVw17jbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8a7112b-9517-4fe0-a7e4-c1d4f6436abc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIhTq4nIdqx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fd5ebb3-e18c-48db-a4e1-c51fce3e2caa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12, 4, 1) (8, 1)\n",
            "torch.Size([2, 3, 4]) torch.Size([3, 8])\n"
          ]
        }
      ],
      "source": [
        "# What are strides. And how are they related to shapes?\n",
        "print(t.stride(), r.stride())\n",
        "print(t.shape, r.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uum4hxYkffli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "551a0044-2362-46d1-e75f-71bc032805fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[4., 0., 2., 5.],\n",
              "         [2., 4., 5., 4.],\n",
              "         [5., 7., 2., 2.]],\n",
              "\n",
              "        [[0., 8., 8., 2.],\n",
              "         [2., 7., 5., 7.],\n",
              "         [5., 2., 2., 1.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Let's try that again without doing the operations in place\n",
        "t.random_(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJM4es_M-p2Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30a13450-b6e0-4c60-8412-958226a0ec2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Not in place\n",
        "r = t.view(3, 8)\n",
        "r = torch.zeros_like(r)\n",
        "r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ivw8wI5U-12D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b78b7408-6fdd-4335-dcd4-434ac59b1fa5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[4., 0., 2., 5.],\n",
              "         [2., 4., 5., 4.],\n",
              "         [5., 7., 2., 2.]],\n",
              "\n",
              "        [[0., 8., 8., 2.],\n",
              "         [2., 7., 5., 7.],\n",
              "         [5., 2., 2., 1.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJdGqvwTdiMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "431c79f0-2664-4af2-f5c2-059396060993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12, 4, 1) (8, 1)\n"
          ]
        }
      ],
      "source": [
        "# What are strides?\n",
        "print(t.stride(), r.stride())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6Fcui7u7jbs"
      },
      "outputs": [],
      "source": [
        "# This *is* important\n",
        "s = r.clone()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rm9a0zci7jbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c4bc45f-d6b0-475a-9ad2-6cc10d1e962f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# In-place fill of 1's\n",
        "s.fill_(1)\n",
        "s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1K3hywm7jbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5af41c12-89ec-4f55-b921-c26a933e7e9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Because we cloned r, even though we did an in-place operation, this doesn't affect r\n",
        "r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir1URH3v7jbt"
      },
      "source": [
        "## Vectors (1D Tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRCvA1R17jbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8a24176-2ea2-45aa-f601-c8926a3637ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# Creates a 1D tensor of integers 1 to 4\n",
        "v = torch.Tensor([1, 2, 3, 4])\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmkSLrIi7jbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "104b0ceb-a405-4cc8-c8c8-6b23b833ade5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dim: 1, size: 4\n"
          ]
        }
      ],
      "source": [
        "# Print number of dimensions (1D) and size of tensor\n",
        "print(f'dim: {v.dim()}, size: {v.size()[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K03oi68R7jbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ec72f9e-80f8-4deb-ab92-87c62d692387"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 0., 2., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "w = torch.Tensor([1, 0, 2, 0])\n",
        "w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGGpVC_b7jbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa203300-0bef-42b4-ca5c-d75efd343249"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 0., 6., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# Element-wise multiplication\n",
        "v * w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pq7-Aqs_7jbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36883b93-cbc6-4446-ab44-c8a01ad778d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Scalar (dot) product: 1*1 + 2*0 + 3*2 + 4*0\n",
        "v @ w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-oXbFTO7jbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb2483e5-8d45-4275-ed41-d2cd01385dc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4., 2., 3., 9., 7.])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# In-place replacement of random number from 0 to 10\n",
        "x = torch.Tensor(5).random_(10)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00BUa-L47jbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "047fd388-22c2-4756-aaf7-d9d649e33a1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first: 4.0, last: 7.0\n"
          ]
        }
      ],
      "source": [
        "print(f'first: {x[0]}, last: {x[-1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZX_Uy_T17jbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60138d37-cfd2-4d4b-a9fc-c870fe071756"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# Extract sub-Tensor [from:to)\n",
        "x[1:2 + 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPNJt5Kt7jbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4521c60c-aeab-47e1-d13c-7ea057b40aac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# Create a tensor with integers ranging from 1 to 4 (both included)\n",
        "v = torch.arange(1, 5)\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_nwZPg-7jbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cce0dcf-5dac-422f-e115-5b25fd055b82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1,  4,  9, 16]) tensor([1, 2, 3, 4])\n"
          ]
        }
      ],
      "source": [
        "# Square all elements in the tensor\n",
        "print(v.pow(2), v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De7wobZv7jbv"
      },
      "source": [
        "## Matrices (2D Tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuiyP0MK7jbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3146853f-e3eb-4f4b-aa40-cad870d8bc9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 5., 3., 7.],\n",
              "        [4., 2., 1., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# Create a 2x4 tensor\n",
        "m = torch.Tensor([[2, 5, 3, 7],\n",
        "                  [4, 2, 1, 9]])\n",
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xI36U8sv7jbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8703b215-d154-441a-c5be-5b4c09f38501"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "m.dim()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7f91z4dw7jbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2f11f68-61fc-4b9b-bc68-7caba00c786c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 -- 4 -- torch.Size([2, 4])\n"
          ]
        }
      ],
      "source": [
        "print(m.size(0), m.size(1), m.size(), sep=' -- ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vuLnT2z7jbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "893eaf1a-5172-4f25-fe34-e2016131fc5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# Indexing row 0, column 2 (0-indexed)\n",
        "m[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLIC7pG97jbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7011565-b05c-467b-ed25-00e526979673"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# Indexing row 0, column 2 (0-indexed)\n",
        "m[0, 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsutF_zc7jbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3c3f7cb-e8ff-4283-845a-60bf5ae81b1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# Indexing column 1, all rows (returns size 2)\n",
        "m[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLg24cHx7jbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9303f558-12c3-425d-d447-80f90bd2a697"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5.],\n",
              "        [2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# Indexing column 1, all rows (returns size 2x1)\n",
        "m[:, [1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8nu79EU7jbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af58b602-8cb8-4ef2-b944-ba1f0a873051"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 5., 3., 7.]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# Indexes row 0, all columns (returns 1x4)\n",
        "m[[0], :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYVpTC7l7jbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8132457-33b8-4cee-9a80-51dc6ddb8394"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# Create tensor of numbers from 1 to 5)\n",
        "v = torch.arange(1., 5)\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UQd3S3w7jbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a3058c4-712c-4838-94b3-79dfeaf7d514"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 5., 3., 7.],\n",
              "        [4., 2., 1., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c10o4XUQ7jbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5972061-647c-4d27-99ea-f6c1e1d9b472"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([49., 47.])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# Scalar product\n",
        "m @ v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEkCtsZG7jbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "826dbc44-221f-43c0-b340-0046a3dbb1df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(49.)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "# Calculated by 1*2 + 2*5 + 3*3 + 4*7\n",
        "m[0, :] @ v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzxKEjus7jby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af77f739-652d-479e-c976-b6559d36eef2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([47.])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# Calculated by\n",
        "m[[1], :] @ v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mP7c5qI17jby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a7e000-62cf-4505-f284-b7c074254c57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.6135, 5.7566, 3.7758, 7.6680],\n",
              "        [4.8418, 2.0838, 1.4398, 9.8291]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# Add a random tensor of size 2x4 to m\n",
        "m + torch.rand(2, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nli9YIb17jby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "645b13f4-57e0-45f4-8814-8a86e328255e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.1163, 4.7426, 2.1023, 6.4566],\n",
              "        [3.2223, 1.9291, 0.7129, 8.4718]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# Subtract a random tensor of size 2x4 to m\n",
        "m - torch.rand(2, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0QPbbr87jby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e2663f3-afe6-4b37-9d48-c40606c0d548"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5049, 2.8269, 0.4347, 1.7500],\n",
              "        [1.9049, 1.1604, 0.4738, 8.1942]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "# Multiply a random tensor of size 2x4 to m\n",
        "m * torch.rand(2, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRxwhq3p7jby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b595de62-95c2-4da8-c62d-1a8c820c3f34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[37.1718, 28.7888,  5.8309, 22.0199],\n",
              "        [13.4459,  3.7475,  1.4755, 10.0797]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "# Divide m by a random tensor of size 2x4\n",
        "m / torch.rand(2, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFjUamkg7jby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5fd173e-3045-4963-d5b5-a0cb3ae0e293"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "m.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88uWT_-N7jbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d4e4861-66e0-4012-a31f-9e9563d3b00b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 4.],\n",
              "        [5., 2.],\n",
              "        [3., 1.],\n",
              "        [7., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "# Transpose tensor m, which is essentially 2x4 to 4x2\n",
        "m.t()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfx8uRtl7jbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1984f965-818c-44b0-e611-6f7b1c9215b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 4.],\n",
              "        [5., 2.],\n",
              "        [3., 1.],\n",
              "        [7., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "# Same as\n",
        "m.transpose(0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Same as\n",
        "m.transpose(1, 0)"
      ],
      "metadata": {
        "id": "7FKRAnqU9JrZ",
        "outputId": "5973059f-4e53-4b99-ab43-6135410dafa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 4.],\n",
              "        [5., 2.],\n",
              "        [3., 1.],\n",
              "        [7., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p2bHHeHJewn"
      },
      "source": [
        "## Broadcasting\n",
        "\n",
        "Two tensors are “broadcastable” if the following rules hold:\n",
        "\n",
        "*   Each tensor has at least one dimension.\n",
        "*   When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPyg44mxJeHP"
      },
      "outputs": [],
      "source": [
        "x=torch.empty(5,7,3)\n",
        "y=torch.empty(5,7,3)\n",
        "# x and y are broadcastable since all dimensions are equal\n",
        "\n",
        "x=torch.empty((0,))\n",
        "y=torch.empty(2,2)\n",
        "# x and y are not broadcastable, because x does not have at least 1 dimension\n",
        "\n",
        "x=torch.empty(5,3,4,1)\n",
        "y=torch.empty(  3,1,1)\n",
        "# x and y are broadcastable.\n",
        "# 1st trailing dimension: both have size 1\n",
        "# 2nd trailing dimension: y has size 1\n",
        "# 3rd trailing dimension: x size == y size\n",
        "# 4th trailing dimension: y dimension doesn't exist\n",
        "\n",
        "# but:\n",
        "x=torch.empty(5,2,4,1)\n",
        "y=torch.empty(  3,1,1)\n",
        "# x and y are not broadcastable, because in the 3rd trailing dimension 2 != 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpudbDP9MI4U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21194076-7613-450a-f4fc-77baff73d88e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3, 4, 1])\n",
            "torch.Size([3, 1, 7])\n"
          ]
        }
      ],
      "source": [
        "# How is the output dimension calculated?\n",
        "x=torch.empty(5,1,4,1)\n",
        "y=torch.empty(3,1,1)\n",
        "print((x+y).size())\n",
        "\n",
        "x=torch.empty(1)\n",
        "y=torch.empty(3,1,7)\n",
        "print((x+y).size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpCZhT8U7jbz"
      },
      "source": [
        "## Constructors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYn7XeYu7jbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6664ff7b-b518-4598-e185-3d7dbeab1def"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 4., 5., 6., 7., 8.])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "# Create tensor from 3 to 8\n",
        "torch.arange(3., 8 + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH8X7Dts7jbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87ca395d-a592-4cfa-dce8-40373fb41edb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5.7000,  2.7000, -0.3000])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "# Create tensor from 5.7 to -2.1 with step -3\n",
        "torch.arange(5.7, -2.1, -3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B14Dyrn7jbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fb1100f-1a9e-4c78-a8af-f9d86e15c9ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.0000, 3.2632, 3.5263, 3.7895, 4.0526, 4.3158, 4.5789, 4.8421, 5.1053,\n",
              "         5.3684, 5.6316, 5.8947, 6.1579, 6.4211, 6.6842, 6.9474, 7.2105, 7.4737,\n",
              "         7.7368, 8.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "# returns a 1D tensor of equally spaced elements between start=3, end=8 and number of elements=20\n",
        "torch.linspace(3, 8, 20).view(1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb4KEmjU7jb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a8c7eef-6855-47f4-bee7-84a2eee41c7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "# Create a tensor filled with 0's\n",
        "torch.zeros(3, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrOxrng27jb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62b9e723-f0dd-40ac-e0d2-d60669b6e006"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "# Create a tensor filled with 1's\n",
        "torch.ones(3, 2, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xt6VUo1A7jb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7723785-3f74-4cf6-bdfb-41d6ac141b01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "# Create a tensor with the diagonal filled with 1\n",
        "torch.eye(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDCnuhOf7jb0"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (20,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81dgFtq67jb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "outputId": "e619a3d5-8532-47d7-f2f5-dd18d445ff96"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Numpy bridge!\n",
        "plt.hist(torch.randn(1000).numpy(), 100);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBhx09297jb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "outputId": "98c8f899-bb22-4ed6-d3fe-e5e9aa408728"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.hist(torch.randn(10**6).numpy(), 100);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyeN3wTV7jb1"
      },
      "source": [
        "## Casting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxMGbcNP7jb1"
      },
      "outputs": [],
      "source": [
        "# Helper to get what kind of tensor types- Changing the data type\n",
        "torch.*Tensor?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6pXTH4b7jb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b1fcf1a-15b1-401a-8096-315860ba0900"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 5., 3., 7.],\n",
              "        [4., 2., 1., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "m = torch.Tensor([[2, 5, 3, 7],\n",
        "                  [4, 2, 1, 9]])\n",
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TAG0hTN7jb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb4c1e74-bc06-4995-d83a-0443fb9a90e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 5., 3., 7.],\n",
              "        [4., 2., 1., 9.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "# This is basically a 64 bit float tensor\n",
        "m_double = m.double()\n",
        "m_double"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFe9nMZi7jb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "677be1a3-93d7-4003-d113-b6a65bee1ebc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 5, 3, 7],\n",
              "        [4, 2, 1, 9]], dtype=torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "# This creates a tensor of type int8\n",
        "m_byte = m.byte()\n",
        "m_byte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSVzhX_I7jb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17814371-e303-4267-c3c6-79caed2cb36d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2., 5., 3., 7.],\n",
              "       [4., 2., 1., 9.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "# Converts tensor to numpy array\n",
        "m_np = m.numpy()\n",
        "m_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHfSv9BB7jb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a5add62-14e4-4387-ff9a-1e3d990265fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.,  5.,  3.,  7.],\n",
              "       [ 4.,  2.,  1.,  9.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "# In-place fill of column 0 and row 0 with value -1\n",
        "m_np[0, 0] = -1\n",
        "m_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICAeMZLU7jb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2043a3fc-e350-46d6-df05-bf07699b3107"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.,  5.,  3.,  7.],\n",
              "        [ 4.,  2.,  1.,  9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CStd3ORV7jb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce10f1cb-8b5a-4ae5-df83-6114c60be512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4] tensor([0, 1, 2, 3, 4])\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor of integers ranging from 0 to 4\n",
        "import numpy as np\n",
        "n_np = np.arange(5)\n",
        "n = torch.from_numpy(n_np)\n",
        "print(n_np, n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gGi0E-h7jb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21b7cb1f-f4c5-4c1c-b048-81e5c0276bb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 2 4 6 8] tensor([0, 2, 4, 6, 8])\n"
          ]
        }
      ],
      "source": [
        "# In-place multiplication of all elements by 2 for tensor n\n",
        "n.mul_(2)\n",
        "print(n_np, n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yGGuawb7jb3"
      },
      "source": [
        "## Using the GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3cSABmzDda2"
      },
      "outputs": [],
      "source": [
        "# If this cell fails you need to change the runtime of your colab notebook to GPU\n",
        "# Go to Runtime -> Change Runtime Type and select GPU\n",
        "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
        "\n",
        "# use the first gpu available if possible\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rQvVYDMFIAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f5ef62e-c1d5-46b7-b477-62c2ab022bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor's device: cpu\n",
            "tensor's device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Tensors can be moved between gpu and cpu memory\n",
        "\n",
        "tensor = torch.randn(5, 5) # create a 5x5 matrix filled with random numbers\n",
        "print(f\"tensor's device: {tensor.device}\") # by default tensors are stored in cpu memory (RAM)\n",
        "\n",
        "# Move your tensor to GPU device 0 if there is one (first GPU in the system)\n",
        "if torch.cuda.is_available():\n",
        "    tensor = tensor.to(device) # tensor.cuda() is an alternative although not recommended\n",
        "print(f\"tensor's device: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccZpZ5xzZ8Sy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "6cc0c40f-9bc2-4536-c5f7-e9e43ac1321d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-4e23d4f2d287>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# This throws an exception, since you can't operate on tensors stored in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# different devices, and the error message is pretty clear about that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ],
      "source": [
        "# A common mistake\n",
        "a = torch.randn(5, 2, device=device)\n",
        "b = torch.randn(1, 2)\n",
        "\n",
        "# This throws an exception, since you can't operate on tensors stored in\n",
        "# different devices, and the error message is pretty clear about that\n",
        "c = a * b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x59Bo0QnEUOU"
      },
      "source": [
        "# Gradient Computation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H25IsxuRKlry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd63265-ad1b-474e-e91e-fb5b5f2ab58d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of L with respecto to a: tensor([36., 81.])\n"
          ]
        }
      ],
      "source": [
        "# Tensors also track the operations applied on them in order to differentiate them\n",
        "\n",
        "# setting requires_grad to true tells the autograd engine that we want to compute\n",
        "# gradients for this tensor\n",
        "a = torch.tensor([2., 3.], requires_grad=True)\n",
        "\n",
        "L = 3*a**3\n",
        "L.sum().backward()  # Convert to scalar before back-propagation\n",
        "print(f\"Gradient of L with respecto to a: {a.grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnviODjmRdKC"
      },
      "source": [
        "Lets check if the computed gradients are correct:\n",
        "\n",
        "$\\frac{\\partial{L}}{\\partial{a}} = [9 * a_1^2, 9 * a_2^2]$\n",
        "\n",
        "$\\frac{\\partial{L}}{\\partial{a}} = [9 * 2^2, 9 * 3^2]$\n",
        "\n",
        "$\\frac{\\partial{L}}{\\partial{a}} = [36, 81]$\n",
        "\n",
        "As we can see the gradient vector matches the one computed by the autograd engine (no surprise there)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61qpDwtvU_E8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f533061b-e975-4ed1-ac9f-eaf380bc9aa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Does a require gradients? : False\n",
            "Does b require gradients?: True\n"
          ]
        }
      ],
      "source": [
        "# Notice that the output tensor of an operation will require gradients even\n",
        "# if only a single input tensor has requires_grad=True.\n",
        "\n",
        "x = torch.rand(5, 5)\n",
        "y = torch.rand(5, 5)\n",
        "z = torch.rand((5, 5), requires_grad=True)\n",
        "\n",
        "a = x + y\n",
        "print(f\"Does a require gradients? : {a.requires_grad}\")\n",
        "b = x + z\n",
        "print(f\"Does b require gradients?: {b.requires_grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq_YCBR4yIYI"
      },
      "source": [
        "# Autograd with Pytorch: Repeat previous exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "Let's repeat with PyTorch one of the gradient calculations what we already did before outselves (with our own auto-differentiation engine):"
      ],
      "metadata": {
        "id": "RsBFjVXQO_jA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uN2Jff2gyIYI",
        "outputId": "64f92bfd-7ef4-4d3f-a337-898d75bee0e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result = tensor(28., grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor(4.0, requires_grad = True)  # a = 4\n",
        "b = torch.tensor(3.0, requires_grad = True)  # b = 3\n",
        "c = a + b        # c = 4 + 3\n",
        "\n",
        "res = a * c      # res = a * c = 28\n",
        "\n",
        "print(\"Result =\", res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hfDIYY5yIYJ"
      },
      "source": [
        "See the warning that the next cell will produce:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwt2meXeyIYJ",
        "outputId": "2ab28418-db91-45d3-9dc8-5198b210af70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The derivative of the result with respect to a is: tensor(11.)\n",
            "The derivative of the result with respect to b is: tensor(4.)\n",
            "The derivative of the result with respect to c is: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-93-46824604471b>:8: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  print(\"The derivative of the result with respect to c is:\", c.grad)\n"
          ]
        }
      ],
      "source": [
        "# Call backprop on the result\n",
        "res.backward()\n",
        "\n",
        "# Now all variables should contain in their \"grad\" the derivative d(res) / d(variable)\n",
        "print(\"The derivative of the result with respect to a is:\", a.grad)\n",
        "print(\"The derivative of the result with respect to b is:\", b.grad)\n",
        "# Also for intermediate results\n",
        "print(\"The derivative of the result with respect to c is:\", c.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chEBBK46yIYJ"
      },
      "source": [
        "There are three different things to understand here. PyTorch by default only calculates gradients for the leaf nodes of the computation graph. To do that, all nodes that are necessary for the computation require their gradient to be computed, but the gradient is not maintained, they do not have a `grad` variable. We can ask PyTorch to create a `grad` variable and save the gradient in these intermediate nodes though, if for some reason we are interested in accessing it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GB3ybQNhyIYJ",
        "outputId": "6178b998-6ddf-459d-b43e-c5c7b3d82f75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "c.requires_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XO5g_uAXyIYK",
        "outputId": "2702060f-897e-4eeb-ba8f-a528aebe97cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "c.retains_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xyteFnUyIYK",
        "outputId": "a670260d-7c32-4b82-9d01-eef95ac24bd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "c.is_leaf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxPwYuI3yIYK",
        "outputId": "2d40d136-0814-4a8c-d55b-f14dd061b4c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requires Grad: True\tRetains Grad: True\tIs leaf: False\n"
          ]
        }
      ],
      "source": [
        "c.retain_grad()\n",
        "\n",
        "print(f\"Requires Grad: {c.requires_grad}\\tRetains Grad: {c.retains_grad}\\tIs leaf: {c.is_leaf}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1uxcO-1yIYK",
        "outputId": "ab263103-adbf-447e-927c-0069d81e3664",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result = tensor(28., grad_fn=<MulBackward0>)\n",
            "The derivative of the result with respect to a is: tensor(11.)\n",
            "The derivative of the result with respect to b is: tensor(4.)\n",
            "The derivative of the result with respect to c is: tensor(4.)\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor(4.0, requires_grad = True)  # a = 4\n",
        "b = torch.tensor(3.0, requires_grad = True)  # b = 3\n",
        "c = a + b        # c = 4 + 3\n",
        "c.retain_grad()\n",
        "\n",
        "res = a * c      # res = a * c = 28\n",
        "\n",
        "print(\"Result =\", res)\n",
        "\n",
        "# Call backprop on the result\n",
        "res.backward()\n",
        "\n",
        "# Now all variables should contain in their \"grad\" the derivative d(res) / d(variable)\n",
        "print(\"The derivative of the result with respect to a is:\", a.grad)\n",
        "print(\"The derivative of the result with respect to b is:\", b.grad)\n",
        "# Also for intermediate results\n",
        "print(\"The derivative of the result with respect to c is:\", c.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-_70bB17jb4"
      },
      "source": [
        "## Much more\n",
        "\n",
        "There's definitely much more, but this was the basics about `Tensor`s fun.\n",
        "\n",
        "*Torch* full API can be found [here](https://pytorch.org/docs/stable/index.html).\n",
        "You'll find 100+ `Tensor` operations, including transposing, indexing, slicing, mathematical operations, linear algebra, random numbers, etc are described."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xl6U-RoEtY3"
      },
      "source": [
        "# Homework\n",
        "\n",
        "<font color=\"blue\">**Exercise 1:** The code below simulates a tiny neural network, however it throws an exception. As you build neural networks in PyTorch you will see this exception often. Look at the error message, explain whats happening and make the necessary changes to the code to get an output from this tiny network</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aGsG2MMGebg",
        "outputId": "c8ca1db3-afb4-4910-9d78-0e4c17d9cb89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.6619]])\n",
            "torch.Size([1, 1]) torch.Size([1, 1])\n"
          ]
        }
      ],
      "source": [
        "### Generate some data\n",
        "torch.manual_seed(7) # Set the random seed so things are predictable\n",
        "\n",
        "# Features are 5 random normal variables\n",
        "features = torch.randn((1, 5))\n",
        "# True weights for our data, random normal variables again\n",
        "weights = torch.randn_like(features)\n",
        "# Transpose weights to have shape (5, 1)\n",
        "weights = weights.T\n",
        "# and a true bias term\n",
        "bias = torch.randn((1, 1))\n",
        "fts = torch.mm(features, weights)\n",
        "print(fts + bias)\n",
        "print(fts.shape, bias.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoV3PxbRyIYY"
      },
      "source": [
        "<font color=\"blue\">**Exercise 2:** Once you manage to sucessfully run the code above notice how the shape of the tensors ```fts``` and ```bias``` are drastically different, yet they can be added together. Which internal PyTorch mechanism makes this addition happen?</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZrd2J_WyIYY"
      },
      "source": [
        "---\n",
        "\n",
        "The reason why `fts` and `bias` can be added together, even though they have different shapes, is because of **broadcasting** in PyTorch. Broadcasting is a rule that allows PyTorch to automatically expand smaller tensors so that their shapes match when performing element-wise operations like addition. In this case, `fts` has a shape of **(1,1)** and `bias` also has a shape of **(1,1)**, so they match perfectly. But if `bias` had a shape of just **(1,)** (a single value), PyTorch would automatically \"stretch\" it to match the shape of `fts`, without actually copying data. This makes operations more efficient and allows us to write cleaner code without manually reshaping tensors.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8N-hhzmQZaA"
      },
      "source": [
        "# More Homework\n",
        "\n",
        "<font color=\"blue\">**Exercise 3:** Answer the following questions about the cell below</font>\n",
        "\n",
        "1. Does the value of ```t``` change? Why?\n",
        "2. Does the shape of ```t``` change? Why?\n",
        "3. Explain, in your own words. What is the stride of a tensor, why is it convenient to have them?\n",
        "4.  Pick a mathematical operation like cosine or square root (not those though 🙂). Can you find the correspoding function in the [torch library](https://https://pytorch.org/docs/stable/torch.html#pointwise-ops).\n",
        "5. Apply the function element-wise to ```a```.\n",
        "6. Is there a version of the function that operates in place? Does it return an error? Why? How can it be fixed?\n",
        "7. Run the same function on the GPU. Do you notice any difference in runtime? If not, why do you think that is?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__SC70eiXYn1",
        "outputId": "47d2ae1e-82a3-4c95-8b53-adad4133a6d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  2,  4],\n",
              "        [ 6,  8, 10],\n",
              "        [12, 14, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "t = torch.tensor(list(range(9)))\n",
        "\n",
        "a = t.view(3, 3)\n",
        "a.mul_(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answers\n",
        "Question 1:\n",
        "Yes, the value of t does change. This happens because `a` is created using `t.view(3, 3)`, which does not create a new copy of `t`, but rather a different way of looking at the same data. When we use `a.mul_(2)`, the multiplication is done in-place, meaning it modifies the original memory where `t` is stored.\n",
        "\n",
        "\n",
        "Question 2:\n",
        "No, the shape of `t` does not change. Even though a has a different shape (3,3), it is only a different \"view\" of `t`, and the underlying data remains the same. The shape of `t` stays (9,) because views do not modify the actual memory layout.\n",
        "\n",
        "\n",
        "Question 3:\n",
        "The stride of a tensor tells us how many steps (memory locations) we need to move in each dimension to reach the next element. For example, if a tensor is stored in row-major order, the stride will indicate how far to jump to get to the next row or column.\n",
        "\n",
        "Strides are convenient because they allow PyTorch to create views of tensors without copying data, making operations faster and more memory-efficient.\n",
        "\n",
        "Question 4 and 5:\n",
        "This mathematical operation applies the exponential function element-wise to a.\n"
      ],
      "metadata": {
        "id": "1ITbi2zpZNbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.exp(a)\n"
      ],
      "metadata": {
        "id": "0vI3S197aisk",
        "outputId": "b012d689-a2bb-44d6-893a-cfa9463d9e59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000e+00, 7.3891e+00, 5.4598e+01],\n",
              "        [4.0343e+02, 2.9810e+03, 2.2026e+04],\n",
              "        [1.6275e+05, 1.2026e+06, 8.8861e+06]])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6:\n",
        "\n",
        "The in-place exponential function gives an error because `a` has integers. In-place functions can’t change the data type, but exponentiation usually turns numbers into decimals (floats). Since `a` is made of whole numbers, it can’t store the new values without changing its type, which isn’t allowed in-place."
      ],
      "metadata": {
        "id": "4H2jnzdqbQJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a.exp_()"
      ],
      "metadata": {
        "id": "SdwWYQzMk2AI",
        "outputId": "cfd29775-d93c-44b2-a331-358df07bf6c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "result type Float can't be cast to the desired output type Long",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-f88a4f822ed4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: result type Float can't be cast to the desired output type Long"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As I mentioned, we need to convert it to float. Above we'll try it and esnure that it works:"
      ],
      "metadata": {
        "id": "kwomRrrulKre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = a.float()\n",
        "a.exp_()"
      ],
      "metadata": {
        "id": "OQAcpiIQlT1M",
        "outputId": "2647c213-1e0f-4185-94aa-8df9f706b5cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000e+00, 7.3891e+00, 5.4598e+01],\n",
              "        [4.0343e+02, 2.9810e+03, 2.2026e+04],\n",
              "        [1.6275e+05, 1.2026e+06, 8.8861e+06]])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7:\n",
        "\n",
        "In the code above we'll see the main difference in the runtime, GPU processes elements in parallel and by that it descreases the computation time.\n",
        "\n",
        "But, if the operation is not highly parallelizable, the advantages of GPU are reduced."
      ],
      "metadata": {
        "id": "3bF42mj9k04Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# CPU test\n",
        "cpu = torch.randn(10000, 10000)\n",
        "start = time.time()\n",
        "torch.exp(cpu)\n",
        "final = time.time()\n",
        "print(\"CPU time:\", final - start)\n",
        "\n",
        "# GPU test\n",
        "gpu = cpu.to(device)\n",
        "torch.cuda.synchronize()\n",
        "start = time.time()\n",
        "torch.exp(gpu)\n",
        "torch.cuda.synchronize()\n",
        "final = time.time()\n",
        "print(\"GPU time:\", final - start)\n"
      ],
      "metadata": {
        "id": "y2sVzbG2lo7H",
        "outputId": "5e4187b8-5b6f-4c53-caf0-5efe4b7d26dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU time: 0.2661440372467041\n",
            "GPU time: 0.05173301696777344\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}