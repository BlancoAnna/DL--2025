{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BlancoAnna/DL--2025/blob/main/Problems%205%20-%20MLPs%20for%20Images/P5_MLP_for_Images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfThKmdJcJvs"
      },
      "source": [
        "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/dkaratzas/DL2022-23/blob/main/Problems%204%20-%20MLP%20for%20Images/P4_MLP_for_Images.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDXy4Tw41nhs"
      },
      "source": [
        "# MLP for image classification\n",
        "\n",
        "In this notebook we are going to learn how to use a Multi-Layer Perceptron (MLP) (Fully-Connected, Feed-Forward Network) for classifying images.\n",
        "\n",
        "An MLP like the ones you used in the notebook of last week can be used with any kind of input data if we can represent it as a vector of real numbers. The shape of the input vector determines the size of the first layer in the model.\n",
        "\n",
        "In the case of images (2D arrays of pixel values) we can get fixed-length vectors by: (1) using always images of the same size, and (2) flatenning the images into a 1D array. The flatten operation collapses an array into one dimension. For example, if we have a grayscale image of $28\\times28$ pixels, its flattened version is a 1d array of $784$ pixel values. Now we can fed these $784$ values into a MLP for classifiying the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA11sg141nhu"
      },
      "source": [
        "### Import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YIr2ty0tFA4C"
      },
      "outputs": [],
      "source": [
        "import torch #should be installed by default in any colab notebook\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOd19Vsh1nhw"
      },
      "source": [
        "### Use GPU if available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWLIxo9Oigfo"
      },
      "outputs": [],
      "source": [
        "# If this cell fails you need to change the runtime of your colab notebook to GPU\n",
        "# Go to Runtime -> Change Runtime Type and select GPU\n",
        "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
        "\n",
        "# use gpu if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI_YXyigdTUC"
      },
      "source": [
        "## The Fashion-MNIST dataset\n",
        "\n",
        "[**Fashion-MNIST**](https://pytorch.org/vision/0.8/datasets.html#fashion-mnist) is a dataset consisting of a training set of $60,000$ examples and a test set of $10,000$ examples. Each example is a $28\\times28$ grayscale image, associated with a label from $10$ classes. It was proposed as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
        "\n",
        "Each training and test example is assigned to one of the following labels: 0 T-shirt/top, 1 Trouser, 2 Pullover, 3 Dress, 4 Coat, 5 Sandal, 6 Shirt, 7 Sneaker, 8 Bag, 9 Ankle boot.\n",
        "\n",
        "The Fashion-MNIST dataset is available in [torchvision](https://pytorch.org/vision/stable/index.html) and can be loaded with the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m7kr-LrSZK7h",
        "outputId": "0f20a093-b6eb-42a6-ec79-5821090db623",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 16.0MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 268kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 4.96MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 12.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])\n",
            "torch.Size([60000]) torch.Size([10000])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_set = datasets.FashionMNIST(\"data\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "val_set = datasets.FashionMNIST(\"data\", train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "print(train_set.data.size(), val_set.data.size())\n",
        "print(train_set.targets.size(), val_set.targets.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aXkcjpbn1nh0",
        "outputId": "6102a9a8-b385-49bd-e4fe-317402e22d1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x600 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# show some images\n",
        "plt.figure(figsize=(16, 6))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    image = train_set.data[i,...]\n",
        "    plt.imshow(image.squeeze().numpy(), cmap=\"gray\")\n",
        "    plt.axis('off');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uji6itK71nh0"
      },
      "source": [
        "<font color=\"blue\">**Exercise 1**: When we loaded the Fashion-MNIST dataset we used the method `transforms.Compose`. Take a look at the documentation of [torchvision.transforms](https://pytorch.org/vision/0.8/transforms.html?highlight=transforms). Is there another transform that we can add to make our classification problem easier?</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCkQ9jX_1nh1"
      },
      "source": [
        "---\n",
        "We can apply various transformations to simplify this classification problem, including RandomHorizontalFlip, ColorJitter, RandomRotation, and RandomResizedCrop, among others.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdJFRmQI1nh1"
      },
      "source": [
        "# Dataloaders\n",
        "\n",
        "Now we introduce a **critical piece in any deep learning training process**: the dataloader. In Pytorch we can create a dataloader for a given dataset as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Aa_bSYB1nh2"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=False, num_workers=0)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=1, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGzwkWcD1nh2"
      },
      "source": [
        "<font color=\"blue\">**Exercise 2**: Take a look at the documentation of [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader) and answer the following questions:</font>\n",
        "\n",
        "<font color=\"blue\">- What are the benefits of a dataloader?</font>\n",
        "\n",
        "<font color=\"blue\">- How can we make the dataloaders defined above better?</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTzLmxGk1nh3"
      },
      "source": [
        "---\n",
        "\n",
        "The `torch.utils.data.DataLoader` offers several key benefits that make handling datasets more efficient. One of its main advantages is automatic batching, which groups data into manageable batches. This simplifies code implementation and enhances training performance by ensuring that the model processes data in an organized manner.  \n",
        "\n",
        "Another significant feature is parallel data loading. By utilizing multiple worker threads, the DataLoader can load data in parallel, effectively reducing wait times and making better use of available CPU resources. This can be particularly beneficial when dealing with large datasets, where loading speed can become a bottleneck.  \n",
        "\n",
        "DataLoader also supports shuffling, which is crucial for preventing the model from learning patterns based on the order of the data rather than the actual features. Shuffling helps improve generalization by ensuring that the model sees varied input sequences during training, reducing the risk of overfitting.  \n",
        "\n",
        "Additionally, memory efficiency is a major advantage. Instead of loading the entire dataset into memory at once, DataLoader fetches data only when needed. This is especially useful for handling large datasets that might otherwise exceed available system memory.  \n",
        "\n",
        "To further optimize the DataLoader, you might consider increasing the number of worker threads, experimenting with different batch sizes, applying data augmentation techniques, and exploring alternative sampling strategies. These adjustments can enhance both training speed and model performance.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E0erJUq1nh3"
      },
      "source": [
        "<font color=\"blue\">**Exercise 3**: Now re-define the datasets and the dataloaders, and introduce normalisation (use the average of image means and stds of the training set for this), turn shuffling on, and use a batch size of 32.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "D_xxk5vj1nh4",
        "outputId": "a395f7d8-fd92-47c7-f43c-a1e5a75f1d90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.2860) tensor(0.3205)\n"
          ]
        }
      ],
      "source": [
        "# Your Code Here\n",
        "mu = 0\n",
        "stdd = 0\n",
        "\n",
        "for i,j in train_set:\n",
        "    mu += i.mean()\n",
        "    stdd += i.std()\n",
        "mu /= len(train_set)\n",
        "stdd /= len(train_set)\n",
        "print(mu, stdd)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mu,stdd,inplace = True)])\n",
        "\n",
        "train_set = datasets.FashionMNIST(\"data\", train=True, download=True, transform=transforms)\n",
        "val_set = datasets.FashionMNIST(\"data\", train=False, download=True, transform=transforms)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True, num_workers=0)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=32, shuffle=True, num_workers=0)"
      ],
      "metadata": {
        "id": "Qyd0TFv_lg4R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the model"
      ],
      "metadata": {
        "id": "jWl0q9Zj2aPr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-WSDzgqcsY4"
      },
      "source": [
        "<font color=\"blue\">**Exercise 4**: Define the class for an MLP with two hidden layers using ReLU activations. The sizes of the input, output and hidden layers should be given during initialisation (using the `__init__()` class constructor parameters).</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uvfwZqcPoAdT"
      },
      "outputs": [],
      "source": [
        "# Your Code Here\n",
        "from torch.nn import ReLU\n",
        "class FCModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(FCModel, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.input_size)\n",
        "        return self.network(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsPUyLUO1nh6"
      },
      "source": [
        "## Parameter Initialization\n",
        "\n",
        "In PyTorch the default parameter initialization depends on the layer type. For example, for the Linear layer the default initialization is defined [here](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/linear.py#L87). Take a look and see if you recognize the initialization method.\n",
        "\n",
        "You can find more initialization methods in the [`torch.nn.init`](https://pytorch.org/docs/stable/nn.init.html?highlight=init) module.\n",
        "\n",
        "If necessary, you can change the default initialization of a layer as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HLSfT6eZcXTI"
      },
      "outputs": [],
      "source": [
        "def initialize_parameters(model):\n",
        "    for name, w in model.named_parameters():\n",
        "        if \"weight\" in name:\n",
        "            nn.init.ones_(w)\n",
        "\n",
        "        if \"bias\" in name:\n",
        "            nn.init.zeros_(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty27ZXvU1nh7"
      },
      "source": [
        "## Create the model and initialize its parameters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_n_params(model, learnable_only=True):\n",
        "  \"\"\"Utility function to count the number of parameters in a model\"\"\"\n",
        "  n_params = [p.numel() for p in model.parameters() if (p.requires_grad or not(learnable_only))]\n",
        "  return sum(n_params)"
      ],
      "metadata": {
        "id": "2ma3r4X-ag30"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "oAoS_kiRZPYT",
        "outputId": "55bd8858-ee15-439c-91a1-13024687f9a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of learnable parameters: 118282\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'device' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a8b7c41f36ea>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# move model to gpu if available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# nn package also has different loss functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
          ]
        }
      ],
      "source": [
        "learning_rate = 1e-3\n",
        "lambda_l2 = 1e-5\n",
        "torch.manual_seed(0) # seed for reproductibility\n",
        "\n",
        "input_size  = 28*28   # images are 28x28 pixels\n",
        "output_size = 10      # there are 10 classes\n",
        "\n",
        "model = FCModel(input_size, 128, output_size)\n",
        "\n",
        "print(f\"Number of learnable parameters: {get_n_params(model)}\")\n",
        "\n",
        "# move model to gpu if available\n",
        "model.to(device)\n",
        "\n",
        "# nn package also has different loss functions.\n",
        "# we use cross entropy loss for our classification task\n",
        "criterion = torch.nn.CrossEntropyLoss() # https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss\n",
        "\n",
        "# we use the optim package to apply\n",
        "# stochastic gradient descent for our parameter updates\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=lambda_l2) # built-in L2\n",
        "\n",
        "# WARNING! What are we doing here?\n",
        "initialize_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe3gLXIX1nh8"
      },
      "source": [
        "## Define the train and validation methods\n",
        "\n",
        "The following code should be easy to follow, but please note the following:\n",
        "\n",
        "Here we use the function `torch.no_grad()` when we want to indicate to PyTorch that we do not want to calculate gradients. This saves a lot of computation and time, and we use it for example when we want to validate our model, when only forward calculations are needed. There are two ways to apply this function, and you can read about it here:\n",
        "https://pytorch.org/docs/stable/generated/torch.no_grad.html\n",
        "\n",
        "The way we use below is called a \"decorator\" function. It is a special super-power of python, and you can read more about it here:\n",
        "https://realpython.com/primer-on-python-decorators/\n",
        "\n",
        "Do not confuse `torch.no_grad()` with `model.eval()` and `model.train()`. The purpose of these two latter functions is to setup our model in different modes. This is very useful if you use layers that work in a different way during training and during evaluation, for example Dropout or Batch Normalisation. The model therefore needs to know how you are using it at any given time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "voDADNIzj4wV"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()  # prevent this function from computing gradients see https://pytorch.org/docs/stable/generated/torch.no_grad.html\n",
        "def validate(criterion, model, loader):\n",
        "\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for data, target in loader:\n",
        "\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        data = data.view(-1, 28*28)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        val_loss += loss.item()\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max logit\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()  # t1.view_as(t2) is equivalent to t1.view(t2.size())\n",
        "\n",
        "    val_loss /= len(loader.dataset)\n",
        "    accuracy = 100. * correct / len(loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        val_loss, correct, len(loader.dataset),\n",
        "        accuracy))\n",
        "\n",
        "\n",
        "    return val_loss\n",
        "\n",
        "\n",
        "def train(epoch, criterion, model, optimizer, loader):\n",
        "\n",
        "    total_loss = 0.0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(loader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        data = data.view(-1, 28*28)\n",
        "\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print loss every N iterations\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(loader.dataset),\n",
        "                100. * batch_idx / len(loader), loss.item()))\n",
        "\n",
        "\n",
        "        total_loss += loss.item()  #.item() is very important here? Why?\n",
        "\n",
        "    return total_loss / len(loader.dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Prc0qFO0SR5"
      },
      "source": [
        "### The training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "psBKsIFAtkXQ",
        "outputId": "b62b9f4d-c6b7-4356-fdf5-af9501794114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'criterion' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b3e53b8a1394>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'criterion' is not defined"
          ]
        }
      ],
      "source": [
        "losses = {\"train\": [], \"val\": []}\n",
        "for epoch in range(10):\n",
        "\n",
        "    train_loss = train(epoch, criterion, model, optimizer, train_loader)\n",
        "    val_loss = validate(criterion, model, val_loader)\n",
        "    losses[\"train\"].append(train_loss)\n",
        "    losses[\"val\"].append(val_loss)\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "\n",
        "    plt.plot(losses[\"train\"], label=\"training loss\")\n",
        "    plt.plot(losses[\"val\"], label=\"validation loss\")\n",
        "\n",
        "    plt.legend()\n",
        "    plt.pause(0.000001)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v345dFG1DA2w"
      },
      "source": [
        "# Visualising Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9GKcptqC_Cq"
      },
      "source": [
        "It may also be useful to visualize some qualitative examples of classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YDjLl_8EC_C6",
        "outputId": "9ba368e8-8a51-4e40-d1d5-dae0f0e6f755",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'device' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-5de6d94b0265>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "\n",
        "    data, target = next(iter(val_loader))\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    data = data.view(-1, 28*28)\n",
        "    output = model(data)\n",
        "    predictions = np.argmax(output.cpu().numpy(), axis=1).tolist()\n",
        "    true = target.cpu().numpy().tolist()\n",
        "\n",
        "    plt.figure(figsize=(16, 6))\n",
        "    for i in range(10):\n",
        "        plt.subplot(2, 5, i + 1)\n",
        "        image = data[i,...].cpu().numpy().reshape((28,28))\n",
        "        plt.imshow(image, cmap=\"gray\")\n",
        "        plt.axis('off')\n",
        "        plt.title('Predicted as {}\\n True label is {}'.format(val_set.classes[predictions[i]], val_set.classes[true[i]], ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcgjBWogo1N1"
      },
      "source": [
        "# Homework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wTgnuL6Btpw"
      },
      "source": [
        "<font color=\"blue\">**Exercise 5**: Change the initialization of the model parameters (this will help a great deal) and train your model on the Fashion-MNIST dataset.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWBimyZV1nh-"
      },
      "outputs": [],
      "source": [
        "# Your Code Here\n",
        "def initialize_parameters(model):\n",
        "    for name, w in model.named_parameters():\n",
        "        if \"weight\" in name:\n",
        "            nn.init.xavier_normal_(w,gain=nn.init.calculate_gain('relu'))\n",
        "        if \"bias\" in name:\n",
        "            nn.init.ones_(w) #I want to have biases, to encourage faster learning during the initial training phase, specially when using relu."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "lambda_l2 = 1e-5\n",
        "torch.manual_seed(0) # seed for reproductibility\n",
        "\n",
        "input_size  = 28*28   # images are 28x28 pixels = 784\n",
        "output_size = 10      # there are 10 classes that we want to classify our images in\n",
        "\n",
        "model = FCModel(input_size, 128, output_size)\n",
        "\n",
        "\n",
        "print(f\"Number of parameters :{get_n_params(model)}\")\n",
        "\n",
        "# move model to gpu if available\n",
        "model.to(device)\n",
        "\n",
        "# nn package also has different loss functions.\n",
        "# we use cross entropy loss for our classification task\n",
        "criterion = torch.nn.CrossEntropyLoss() # https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss\n",
        "\n",
        "# we use the optim package to apply\n",
        "# stochastic gradient descent for our parameter updates\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=lambda_l2) # built-in L2\n",
        "\n",
        "# WARNING! What are we doing here?\n",
        "initialize_parameters(model)\n",
        "#Here we are initializing our parameters using a normal distribution with mean 0 and std deviation = sqrt(2 / (input_neurons + output_neurons)) using Xavier's normal initialization"
      ],
      "metadata": {
        "id": "nndx886Ul4v0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = {\"train\": [], \"val\": []}\n",
        "for epoch in range(10):\n",
        "\n",
        "    train_loss = train(epoch, criterion, model, optimizer, train_loader)\n",
        "    val_loss = validate(criterion, model, val_loader)\n",
        "    losses[\"train\"].append(train_loss)\n",
        "    losses[\"val\"].append(val_loss)\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "\n",
        "    plt.plot(losses[\"train\"], label=\"training loss\")\n",
        "    plt.plot(losses[\"val\"], label=\"validation loss\")\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend()\n",
        "    plt.pause(0.000001)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "o_8MOt5zl6Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "From the plot, we observe that during the first two epochs, both training and validation loss decrease, indicating effective learning. However, from epoch 2 to epoch 6, validation loss starts to rise while training loss continues to decline, suggesting the onset of overfitting.  \n",
        "\n",
        "Beyond epoch 6, training loss continues its downward trend, while validation loss also decreases, albeit at a slower pace. This suggests that the model is beginning to stabilize, as it still improves but at a more gradual rate.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Uvp-sP-fmBh9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2K2J1nB1nh_"
      },
      "outputs": [],
      "source": [
        "# evaluate the trained model on the validation set\n",
        "_ = validate(criterion, model, val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIYShV6MCN9z"
      },
      "source": [
        "<font color=\"blue\">**Exercise 6**: Try to improve the Accuracy of your model on the validation set by adding more layers and/or more hidden units in you model. For example you can use a MLP with 2 hidden layers with 512 and 256 units respectively. You can also consider changing the batch size and learning rate if needed.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWK9OP6m1niA"
      },
      "outputs": [],
      "source": [
        "# Your Code Here\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True, num_workers=0)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=32, shuffle=True, num_workers=0)\n",
        "#FFNN (MLP) with 3 hidden layers of size 512, 256, 512 respecively, all with ReLU activation function.\n",
        "from torch.nn import ReLU\n",
        "class FCModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n",
        "        super(FCModel, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size1),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size1, hidden_size2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size2, hidden_size2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size2, hidden_size3),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size3, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, self.input_size)\n",
        "        return self.network(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "lambda_l2 = 1e-5\n",
        "torch.manual_seed(0) # seed for reproductibility\n",
        "\n",
        "input_size  = 28*28   # images are 28x28 pixels = 784\n",
        "output_size = 10      # there are 10 classes that we want to classify our images in\n",
        "\n",
        "model = FCModel(input_size, 512, 256, 512, output_size)\n",
        "\n",
        "\n",
        "print(f\"Number of parameters :{get_n_params(model)}\")\n",
        "\n",
        "# move model to gpu if available\n",
        "model.to(device)\n",
        "\n",
        "# nn package also has different loss functions.\n",
        "# we use cross entropy loss for our classification task\n",
        "criterion = torch.nn.CrossEntropyLoss() # https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss\n",
        "\n",
        "# we use the optim package to apply\n",
        "# stochastic gradient descent for our parameter updates\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=lambda_l2) # built-in L2\n",
        "\n",
        "# WARNING! What are we doing here?\n",
        "initialize_parameters(model)"
      ],
      "metadata": {
        "id": "prOQOvGGmKhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = {\"train\": [], \"val\": []}\n",
        "for epoch in range(10):\n",
        "\n",
        "    train_loss = train(epoch, criterion, model, optimizer, train_loader)\n",
        "    val_loss = validate(criterion, model, val_loader)\n",
        "    losses[\"train\"].append(train_loss)\n",
        "    losses[\"val\"].append(val_loss)\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "\n",
        "    plt.plot(losses[\"train\"], label=\"training loss\")\n",
        "    plt.plot(losses[\"val\"], label=\"validation loss\")\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend()\n",
        "    plt.pause(0.000001)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2ZSdqSoYmMaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5qQUDJL1niA"
      },
      "outputs": [],
      "source": [
        "# evaluate the trained model on the validation set\n",
        "_ = validate(criterion, model, val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b61J-XQ8CPiW"
      },
      "source": [
        "<font color=\"blue\">**Exercise 7**: Try at least two different [optimizers](https://pytorch.org/docs/stable/optim.html#algorithms) (e.g. SGD with momentum, RMSProp, Adam, etc.) and plot **in a single matplotlib figure** the loss curves for training the model with them. We want them in a single figure to be able to easily compare the three learning curves.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tr1q09A1niB"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "learning_rate = 1e-3\n",
        "lambda_l2 = 1e-5\n",
        "torch.manual_seed(0) # seed for reproductibility\n",
        "\n",
        "input_size  = 28*28   # images are 28x28 pixels\n",
        "output_size = 10      # there are 10 classes\n",
        "\n",
        "model_Adam = FCModel(input_size, 512, 256, 512, output_size) #512 units for first hidden layer and 256 units for second hidden layer\n",
        "\n",
        "model_RMSprop = FCModel(input_size, 512, 256, 512, output_size) #512 units for first hidden layer and 256 units for second hidden layer\n",
        "# nn package also has different loss functions.\n",
        "# we use cross entropy loss for our classification task\n",
        "criterion = torch.nn.CrossEntropyLoss() # https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss\n",
        "\n",
        "# we use the optim package to apply\n",
        "# stochastic gradient descent for our parameter updates\n",
        "first_optimizer = torch.optim.Adam(model_Adam.parameters(), lr=learning_rate, weight_decay=lambda_l2) # built-in L2\n",
        "\n",
        "second_optimizer = torch.optim.RMSprop(model_RMSprop.parameters(), lr=learning_rate, weight_decay=lambda_l2)\n",
        "\n",
        "#Changing the batch size\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True, num_workers=0)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=32, shuffle=True, num_workers=0)\n",
        "\n",
        "# WARNING! What are we doing here?\n",
        "initialize_parameters(model_Adam)\n",
        "initialize_parameters(model_RMSprop)\n",
        "\n",
        "print(f\"Number of parameters in ADAM model: {get_n_params(model_Adam)}\\n\")\n",
        "print(f\"Number of parameters in RMSprop model: {get_n_params(model_RMSprop)}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_Adam.to(device)\n",
        "model_RMSprop.to(device)"
      ],
      "metadata": {
        "id": "TJtXF0tCmS_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the model:\n",
        "\n",
        "losses_1 = {\"train\": [], \"val\": []}\n",
        "losses_2 = {\"train\": [], \"val\": []}\n",
        "for epoch in range(10):\n",
        "\n",
        "    train_loss_1 = train(epoch, criterion, model_Adam, first_optimizer, train_loader)\n",
        "    val_loss_1 = validate(criterion, model_Adam, val_loader)\n",
        "\n",
        "    train_loss_2 = train(epoch, criterion, model_RMSprop, second_optimizer, train_loader)\n",
        "    val_loss_2 = validate(criterion, model_RMSprop, val_loader)\n",
        "\n",
        "    losses_1[\"train\"].append(train_loss_1)\n",
        "    losses_1[\"val\"].append(val_loss_1)\n",
        "\n",
        "    losses_2[\"train\"].append(train_loss_2)\n",
        "    losses_2[\"val\"].append(val_loss_2)\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('loss')\n",
        "\n",
        "    plt.plot(losses_1[\"train\"], label=\"training loss ADAM\")\n",
        "    plt.plot(losses_1[\"val\"], label=\"validation loss ADAM\")\n",
        "\n",
        "    plt.plot(losses_2[\"train\"], label=\"training loss RMSprop\")\n",
        "    plt.plot(losses_2[\"val\"], label=\"validation loss RMSprop\")\n",
        "\n",
        "    plt.legend()\n",
        "    plt.pause(0.000001)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "AAlF18c4mU_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "Adam_results = validate(criterion, model_Adam, val_loader)\n",
        "RMSprop_results = validate(criterion, model_RMSprop, val_loader)\n",
        "print('Adam final loss:', Adam_results)\n",
        "print('RMSprop final loss: ', RMSprop_results)"
      ],
      "metadata": {
        "id": "I8d3rSuTmWyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAPZ1Xv0CQv4"
      },
      "source": [
        "<font color=\"blue\">**Exercise 8**: Calculate the Accuracy for each individual class in the dataset and plot the [confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html#sklearn.metrics.plot_confusion_matrix) of your trained models.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7mFZ1yi1niC"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "def get_predictions_and_labels(model, dataloader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return np.array(all_preds), np.array(all_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_adam, labels_adam = get_predictions_and_labels(model_Adam, val_loader, device)\n",
        "confusion_matrix_adam = confusion_matrix(predictions_adam, labels_adam)\n",
        "predictions_rms, labels_rms = get_predictions_and_labels(model_RMSprop, val_loader, device)\n",
        "confusion_matrix_RMSprop = confusion_matrix(predictions_rms, labels_rms)\n",
        "\n",
        "print(f\"Confusion matrix for Adam model:\\n\\n{confusion_matrix_adam}\\n\\n\\n\")\n",
        "print(f\"Confusion matrix for RMSprop model:\\n\\n{confusion_matrix_RMSprop}\")"
      ],
      "metadata": {
        "id": "prjjjz_Bmd9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_adam = classification_report(predictions_adam, labels_adam)\n",
        "print(report_adam)"
      ],
      "metadata": {
        "id": "-glwgwQimgNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_rms = classification_report(predictions_rms, labels_rms)\n",
        "print(report_rms)"
      ],
      "metadata": {
        "id": "PrmtknXUmjqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "\n",
        "    data, target = next(iter(val_loader))\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    data = data.view(-1, 28*28)\n",
        "    output = model_Adam(data)\n",
        "    predictions = np.argmax(output.cpu().numpy(), axis=1).tolist()\n",
        "    true = target.cpu().numpy().tolist()\n",
        "\n",
        "    plt.figure(figsize=(16, 6))\n",
        "    for i in range(10):\n",
        "        plt.subplot(2, 5, i + 1)\n",
        "        image = data[i, ...].cpu().numpy().reshape((28,28))\n",
        "        plt.imshow(image, cmap=\"gray\")\n",
        "        plt.axis('off')\n",
        "        plt.title('Predicted as {}\\n True label is {}'.format(val_set.classes[predictions[i]], val_set.classes[true[i]], ))"
      ],
      "metadata": {
        "id": "in6WXdyGmlrH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "pytorch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}